---
layout: post
title: "GPU 연결 방식의 이해: PCIe vs SXM"
date: 2025-10-25
category: ai
parent_category: study
learning_framework:
  stage: digestion
  pacer_type: conceptual
tags: [gpu, pcie, sxm, nvidia, hardware]
excerpt: "GPU를 서버에 연결하는 두 가지 방식, PCIe와 SXM의 차이점과 각각의 장단점을 알아봅니다."
---

# GPU 연결 방식의 이해: PCIe vs SXM

GPU를 컴퓨터나 서버에 연결하는 방식은 성능에 큰 영향을 미칩니다. 오늘은 가장 널리 사용되는 두 가지 폼팩터인 PCIe와 SXM의 차이점을 알아보겠습니다.

## 폼팩터란?

폼팩터(Form Factor)는 GPU가 메인보드와 물리적으로 어떻게 연결되는지를 정의하는 규격입니다. 마치 USB-C와 USB-A처럼, 연결 방식에 따라 성능과 호환성이 달라집니다.

## PCIe (Peripheral Component Interconnect Express)

### 개념

PCIe는 컴퓨터 업계의 표준 확장 슬롯 방식입니다. 여러분이 게임용 그래픽카드를 구매해서 PC에 장착할 때 사용하는 바로 그 방식입니다.

### 주요 특징

**물리적 구조**
- 메인보드에 있는 긴 슬롯에 그래픽카드를 수직으로 꽂는 방식
- 일반적인 크기는 x16 레인 (16개의 데이터 통로)

**호환성**
- 거의 모든 PC와 서버 메인보드가 지원
- 표준화된 규격으로 다양한 제조사의 GPU 사용 가능
- 세대 간 하위 호환성 제공 (PCIe 4.0 슬롯에 PCIe 3.0 카드 장착 가능)

### 사용 사례

```plaintext
개인 사용자
└── 게이밍 PC (RTX 4090, RX 7900 XTX 등)
└── 워크스테이션 (영상 편집, 3D 렌더링)

기업 환경
└── 범용 서버
└── 클라우드 인스턴스
└── 소규모 AI/ML 학습
```

**대표 제품**: NVIDIA H100 PCIe 버전, A100 PCIe 버전

## SXM (Server PCI Express Module)

### 개념

SXM은 NVIDIA가 개발한 고성능 서버 전용 폼팩터입니다. "꽂는" 카드 방식이 아니라, 전용 보드에 직접 "장착"하는 모듈 형태입니다.

### 주요 특징

**물리적 구조**
- 전용 HGX 또는 DGX 보드에 직접 솔더링하거나 소켓 방식으로 장착
- PCIe보다 훨씬 더 많은 핀 수와 전력 공급 라인

**성능 우위**

1. **더 빠른 GPU 간 통신**
   - NVLink를 통한 직접 연결 (최대 900GB/s)
   - PCIe 방식 대비 5-10배 빠른 GPU 간 데이터 전송

2. **더 높은 전력 공급**
   - SXM5 기준 최대 700W 공급 가능
   - PCIe 방식은 일반적으로 최대 450W 제한

3. **최적화된 냉각**
   - 전용 냉각 솔루션과 통합 설계
   - 고밀도 배치에서도 안정적인 온도 유지

### 사용 사례

```plaintext
대규모 AI 학습
└── 8-GPU 구성의 통합 시스템
└── LLM 학습 (GPT, LLaMA 등)
└── 대규모 이미지 생성 모델

슈퍼컴퓨터
└── HPC 클러스터
└── 과학 연구용 시뮬레이션
```

**대표 제품**: NVIDIA H100 SXM5, A100 SXM4

## PCIe vs SXM: 직접 비교

| 구분 | PCIe | SXM |
|------|------|-----|
| **호환성** | 표준 메인보드 사용 가능 | 전용 보드 필요 |
| **GPU 간 통신** | PCIe 스위치 경유 (느림) | NVLink 직접 연결 (빠름) |
| **전력 공급** | ~450W | ~700W |
| **확장성** | 제한적 (보통 2-4개) | 우수 (8개 이상) |
| **가격** | 상대적으로 저렴 | 매우 비싸고 전체 시스템 구매 필요 |
| **용도** | 개인/중소규모 | 대규모 AI/슈퍼컴퓨팅 |

## 실무에서의 선택 기준

### PCIe를 선택해야 하는 경우

- 개인 연구자나 소규모 스타트업
- 기존 서버 인프라 활용
- 유연한 GPU 업그레이드가 필요한 경우
- 예산이 제한적인 경우

```python
# 예시: PCIe 환경에서의 멀티 GPU 학습
import torch

if torch.cuda.device_count() > 1:
    model = torch.nn.DataParallel(model)  # PCIe 연결에서도 사용 가능
```

### SXM을 선택해야 하는 경우

- 대규모 AI 모델 학습 (수십억 파라미터 이상)
- 높은 GPU 간 통신 대역폭이 중요한 경우
- 최대 성능이 필요한 HPC 워크로드
- 장기적인 대규모 투자 계획

```python
# 예시: SXM 환경에서의 멀티 GPU 학습
import torch

# NVLink를 활용한 효율적인 분산 학습
model = torch.nn.parallel.DistributedDataParallel(model)
# SXM의 NVLink로 GPU 간 그래디언트 통신 가속
```

## 비유로 이해하기

**PCIe**: 일반 가정용 전기 콘센트
- 표준화되어 있어 어떤 가전제품이든 꽂아 쓸 수 있습니다
- 호환성은 좋지만 공급할 수 있는 전력에 한계가 있습니다

**SXM**: 공장의 고압 전력선
- 특정 기계 전용으로 직접 연결됩니다
- 호환성은 떨어지지만 훨씬 강력한 전력을 공급할 수 있습니다

## 결론

PCIe와 SXM은 각각의 용도에 최적화된 폼팩터입니다. 

- **PCIe**: 범용성과 접근성이 장점. 대부분의 사용자에게 적합
- **SXM**: 최고 성능이 필요한 전문 분야에 특화

개인 연구자나 중소 기업이라면 PCIe 기반 GPU로 시작하는 것이 현명합니다. 대규모 AI 모델 학습이나 HPC 워크로드가 필요한 대기업이나 연구소라면 SXM 기반 시스템 도입을 고려할 수 있습니다.

기술을 선택할 때는 현재의 요구사항뿐만 아니라 향후 확장성과 예산도 함께 고려해야 합니다. 여러분의 프로젝트는 어떤 폼팩터가 적합할까요?
